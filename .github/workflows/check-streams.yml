name: Check M3U Streams

on:
  workflow_dispatch:
    inputs:
      check_vods:
        description: 'Check VOD files (.mkv, .mp4, .avi)'
        required: false
        default: false
        type: boolean
      check_ppv:
        description: 'Check PPV channels (may be offline)'
        required: false
        default: false
        type: boolean
      timeout_seconds:
        description: 'Timeout per stream (seconds)'
        required: false
        default: '10'
        type: string
  schedule:
    - cron: '0 */6 * * *'  # Runs every 6 hours (without VODs/PPV by default)

permissions:
  contents: write

jobs:
  check-streams:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests m3u8

      - name: Check Streams
        env:
          CHECK_VODS: ${{ github.event.inputs.check_vods || 'false' }}
          CHECK_PPV: ${{ github.event.inputs.check_ppv || 'false' }}
          TIMEOUT_SECONDS: ${{ github.event.inputs.timeout_seconds || '10' }}
        run: |
          set -e  # Exit on any error
          python - << 'EOF'
          import requests
          import os
          from datetime import datetime, timezone
          import re
          import time
          import urllib.parse
          
          # Configuration from environment
          CHECK_VODS = os.getenv('CHECK_VODS', 'false').lower() == 'true'
          CHECK_PPV = os.getenv('CHECK_PPV', 'false').lower() == 'true' 
          TIMEOUT_SECONDS = int(os.getenv('TIMEOUT_SECONDS', '10'))
          
          print(f"🔧 Configuration: VODs={CHECK_VODS}, PPV={CHECK_PPV}, Timeout={TIMEOUT_SECONDS}s")
          print(f"📁 Current directory: {os.getcwd()}")
          print(f"📋 Files in directory: {os.listdir('.')}")
          
          def is_vod_url(url):
              """Enhanced VOD detection for multiple patterns"""
              url_lower = url.lower()
              
              # VOD file extensions with various separators
              vod_patterns = [
                  # Hash-based patterns (original)
                  '#.mkv', '#.mp4', '#.avi', '#.mov', '#.wmv', '#.flv', '#.webm', '#.m4v',
                  # Slash-based patterns
                  '.mkv/', '.mp4/', '.avi/', '.mov/', '.wmv/', '.flv/', '.webm/', '.m4v/',
                  # Query parameter patterns
                  '.mkv?', '.mp4?', '.avi?', '.mov?', '.wmv?', '.flv?', '.webm?', '.m4v?'
              ]
              
              # Path-based VOD indicators
              vod_paths = ['/movie/', '/film/', '/vod/', '/videos/', '/content/', '/media/']
              
              # Check file extension patterns
              for pattern in vod_patterns:
                  if pattern in url_lower:
                      return True
              
              # Check path indicators
              for path in vod_paths:
                  if path in url_lower:
                      return True
              
              return False
          
          def is_m3u8_stream(url):
              """Check if URL is an M3U8 stream (handles tokens/parameters)"""
              url_lower = url.lower()
              return '.m3u8' in url_lower and not is_vod_url(url)
          
          def is_ts_stream(url):
              """Check if URL is a TS stream"""
              url_lower = url.lower()
              return '.ts' in url_lower and not is_vod_url(url) and not is_m3u8_stream(url)
          
          def classify_stream_type(url):
              """Classify stream type for reporting"""
              if is_vod_url(url):
                  return 'VOD'
              elif is_m3u8_stream(url):
                  return 'M3U8'
              elif is_ts_stream(url):
                  return 'TS'
              elif 'rtmp' in url.lower():
                  return 'RTMP'
              else:
                  return 'Other'
          
          def is_ppv_channel(name, group):
              """Check if channel is PPV (Pay-Per-View) or Event channel"""
              name_lower = name.lower()
              group_lower = group.lower()
              
              # Specific group matching for your setup
              event_groups = ['uk events', 'usa events', 'events']
              ppv_indicators = ['ppv', 'pay per view', 'boxing', 'ufc', 'wwe']
              
              # Check if group exactly matches event groups
              if any(event_group in group_lower for event_group in event_groups):
                  return True
              
              # Check for PPV indicators in name or group
              return (any(indicator in name_lower for indicator in ppv_indicators) or 
                      any(indicator in group_lower for indicator in ppv_indicators))
          
          def should_skip_stream(stream):
              """Determine if stream should be skipped based on configuration"""
              stream_type = classify_stream_type(stream['url'])
              
              if stream_type == 'VOD' and not CHECK_VODS:
                  return True, "VOD file (skipped)"
              
              if is_ppv_channel(stream['name'], stream['group']) and not CHECK_PPV:
                  return True, "PPV channel (skipped)"
              
              return False, None
          
          def check_stream(url, timeout=10, is_ppv=False):
              """Check if a stream URL is accessible and categorize failures"""
              try:
                  # Enhanced headers for better compatibility
                  headers = {
                      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                      'Accept': '*/*',
                      'Accept-Language': 'en-US,en;q=0.9',
                      'Accept-Encoding': 'gzip, deflate, br',
                      'Connection': 'keep-alive',
                      'Referer': 'https://github.com/',
                      'Sec-Fetch-Dest': 'video',
                      'Sec-Fetch-Mode': 'no-cors',
                      'Sec-Fetch-Site': 'cross-site'
                  }
                  
                  # Adjust timeout for PPV channels (they might be slower)
                  if is_ppv:
                      timeout = min(timeout * 2, 30)
                  
                  # For VOD files, try HEAD first as they're usually static
                  if is_vod_url(url):
                      try:
                          response = requests.head(url, timeout=timeout, headers=headers, allow_redirects=True)
                          if response.status_code < 400:
                              return {"status": "working", "code": response.status_code, "error": None, "type": "VOD"}
                      except:
                          pass
                  
                  # Try GET request with streaming
                  response = requests.get(url, timeout=timeout, headers=headers, stream=True, allow_redirects=True)
                  
                  if response.status_code < 400:
                      # For live streams, try to read a small chunk
                      if not is_vod_url(url):
                          try:
                              chunk = next(response.iter_content(chunk_size=1024), None)
                              if chunk:
                                  stream_type = classify_stream_type(url)
                                  if is_ppv:
                                      stream_type = f"PPV-{stream_type}"
                                  return {"status": "working", "code": response.status_code, "error": None, "type": stream_type}
                              else:
                                  return {"status": "stream_error", "code": response.status_code, "error": "Empty stream response"}
                          except:
                              return {"status": "stream_error", "code": response.status_code, "error": "Stream not readable"}
                      else:
                          return {"status": "working", "code": response.status_code, "error": None, "type": "VOD"}
                  else:
                      # Enhanced error categorization
                      if response.status_code == 403:
                          return {"status": "access_denied", "code": 403, "error": "Access denied (geo-blocked/auth required)"}
                      elif response.status_code == 404:
                          error_msg = "Stream not found"
                          if is_ppv:
                              error_msg += " (PPV may be offline)"
                          return {"status": "not_found", "code": 404, "error": error_msg}
                      elif response.status_code in [500, 502, 503, 504]:
                          return {"status": "server_error", "code": response.status_code, "error": f"Server error ({response.status_code})"}
                      elif response.status_code == 429:
                          return {"status": "rate_limited", "code": 429, "error": "Rate limited"}
                      else:
                          return {"status": "http_error", "code": response.status_code, "error": f"HTTP {response.status_code}"}
                          
              except requests.exceptions.Timeout:
                  error_msg = f"Timeout after {timeout}s"
                  if is_ppv:
                      error_msg += " (PPV may be preparing)"
                  return {"status": "timeout", "code": None, "error": error_msg}
              except requests.exceptions.ConnectionError as e:
                  error_str = str(e)
                  if "Name or service not known" in error_str or "Failed to resolve" in error_str:
                      return {"status": "dns_error", "code": None, "error": "DNS resolution failed"}
                  elif "Connection refused" in error_str:
                      return {"status": "connection_refused", "code": None, "error": "Connection refused"}
                  else:
                      return {"status": "connection_error", "code": None, "error": "Network error"}
              except Exception as e:
                  return {"status": "unknown_error", "code": None, "error": str(e)[:100]}
          
          def parse_m3u(file_path):
              """Parse M3U file and extract stream information"""
              if not os.path.exists(file_path):
                  print(f"File not found: {file_path}")
                  return []
                  
              streams = []
              
              try:
                  with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                      lines = f.readlines()
              except Exception as e:
                  print(f"Error reading {file_path}: {str(e)}")
                  return []
                  
              for i in range(len(lines)):
                  line = lines[i].strip()
                  if line.startswith('#EXTINF'):
                      try:
                          # Extract group-title if present
                          group_match = re.search(r'group-title="([^"]*)"', line)
                          group = group_match.group(1) if group_match else "No Group"
                          
                          # Extract channel name (after last comma)
                          name_part = line.split(',')[-1].strip()
                          name = name_part if name_part else "Unknown Channel"
                          
                          # Get URL from next line
                          if i + 1 < len(lines):
                              url = lines[i + 1].strip()
                              if url and not url.startswith('#') and ('http' in url or 'rtmp' in url):
                                  streams.append({
                                      'name': name,
                                      'url': url,
                                      'group': group
                                  })
                      except Exception as e:
                          print(f"Error parsing line {i}: {str(e)}")
                          continue
              
              return streams
          
          # Initialize counters
          total_streams = 0
          total_m3u8_streams = 0
          total_vod_files = 0
          total_ts_streams = 0
          total_other_streams = 0
          checked_streams = 0
          working_streams = 0
          skipped_streams = 0
          
          # Track working/failed counts by type
          working_by_type = {'M3U8': 0, 'VOD': 0, 'TS': 0, 'RTMP': 0, 'Other': 0}
          failed_by_type = {'M3U8': 0, 'VOD': 0, 'TS': 0, 'RTMP': 0, 'Other': 0}
          
          # Enhanced failure categorization
          categorized_failures = {
              'access_denied': [],
              'timeout': [],
              'dns_error': [],
              'not_found': [],
              'server_error': [],
              'connection_error': [],
              'stream_error': [],
              'http_error': [],
              'rate_limited': [],
              'unknown_error': []
          }
          
          skipped_categories = {
              'vods': [],
              'ppv': []
          }
          
          # M3U files to process
          m3u_files = [
              'channel playlist.m3u'
          ]
          
          print("🚀 Starting enhanced stream check...")
          start_time = datetime.now(timezone.utc)
          
          for m3u_file in m3u_files:
              print(f"📁 Processing {m3u_file}...")
              
              try:
                  streams = parse_m3u(m3u_file)
                  file_total = len(streams)
                  total_streams += file_total
                  
                  # Count streams by type BEFORE skipping logic
                  file_m3u8_count = 0
                  file_vod_count = 0
                  file_ts_count = 0
                  file_other_count = 0
                  
                  for stream in streams:
                      stream_type = classify_stream_type(stream['url'])
                      if stream_type == 'VOD':
                          file_vod_count += 1
                          total_vod_files += 1
                      elif stream_type == 'M3U8':
                          file_m3u8_count += 1
                          total_m3u8_streams += 1
                      elif stream_type == 'TS':
                          file_ts_count += 1
                          total_ts_streams += 1
                      else:
                          file_other_count += 1
                          total_other_streams += 1
                  
                  print(f"Found {file_total} total streams in {m3u_file}:")
                  print(f"  📺 M3U8 Streams: {file_m3u8_count}")
                  print(f"  🎬 VOD Files: {file_vod_count}")
                  print(f"  📡 TS Streams: {file_ts_count}")
                  print(f"  🔗 Other Streams: {file_other_count}")
                  
                  file_working = 0
                  file_skipped = 0
                  
                  for i, stream in enumerate(streams):
                      # Check if stream should be skipped
                      should_skip, skip_reason = should_skip_stream(stream)
                      
                      if should_skip:
                          skipped_streams += 1
                          file_skipped += 1
                          
                          # Show what's being skipped for debugging
                          if "VOD" in skip_reason:
                              print(f"⭕ Skipping VOD: {stream['name'][:40]}")
                          elif "PPV" in skip_reason:
                              print(f"⭕ Skipping PPV: {stream['name'][:40]} (Group: {stream['group']})")
                          
                          # Categorize skipped streams
                          if "VOD" in skip_reason:
                              skipped_categories['vods'].append({
                                  'name': stream['name'],
                                  'group': stream['group'],
                                  'file': m3u_file,
                                  'url': stream['url'][:60] + '...' if len(stream['url']) > 60 else stream['url']
                              })
                          elif "PPV" in skip_reason:
                              skipped_categories['ppv'].append({
                                  'name': stream['name'],
                                  'group': stream['group'],
                                  'file': m3u_file,
                                  'url': stream['url'][:60] + '...' if len(stream['url']) > 60 else stream['url']
                              })
                          
                          if (i + 1) % 100 == 0:  # Progress update every 100 items
                              print(f"Progress: {i+1}/{file_total} processed, {file_skipped} skipped, {checked_streams} checked")
                          continue
                      
                      checked_streams += 1
                      stream_type = classify_stream_type(stream['url'])
                      
                      print(f"🔍 Checking {checked_streams}/{total_streams-skipped_streams}: {stream['name'][:40]}... ({stream_type})")
                      
                      # Determine if this is a PPV channel for special handling
                      is_ppv = is_ppv_channel(stream['name'], stream['group'])
                      
                      result = check_stream(stream['url'], TIMEOUT_SECONDS, is_ppv)
                      
                      if result['status'] == 'working':
                          working_streams += 1
                          file_working += 1
                          working_by_type[stream_type] += 1
                          print(f"  ✅ Working ({result.get('type', stream_type)})")
                      else:
                          print(f"  ❌ Failed: {result['error']}")
                          failed_by_type[stream_type] += 1
                          
                          # Categorize the failure
                          failure_info = {
                              'name': stream['name'],
                              'group': stream['group'],
                              'url': stream['url'][:80] + '...' if len(stream['url']) > 80 else stream['url'],
                              'file': m3u_file,
                              'error': result['error'],
                              'code': result['code'],
                              'type': f"PPV-{stream_type}" if is_ppv else stream_type
                          }
                          
                          if result['status'] in categorized_failures:
                              categorized_failures[result['status']].append(failure_info)
                          else:
                              categorized_failures['unknown_error'].append(failure_info)
                      
                      # Dynamic delay based on success rate
                      if checked_streams % 10 == 0:
                          success_rate = working_streams / checked_streams
                          delay = 0.1 if success_rate > 0.8 else 0.2
                          time.sleep(delay)
                      else:
                          time.sleep(0.05)
                  
                  print(f"📊 File {m3u_file}: {file_working}/{file_total-file_skipped} working, {file_skipped} skipped")
                  
              except Exception as e:
                  print(f"❌ Error processing {m3u_file}: {str(e)}")
                  # Continue processing other files instead of failing
                  continue
          
          # Calculate final statistics
          total_checked = checked_streams
          total_failures = sum(len(failures) for failures in categorized_failures.values())
          working_percentage = (working_streams / total_checked * 100) if total_checked > 0 else 0
          end_time = datetime.now(timezone.utc)
          duration = end_time - start_time
          
          print(f"⏱️ Check completed in {duration.total_seconds():.1f} seconds")
          print(f"📊 Stream Type Summary:")
          print(f"  📺 Total M3U8 Streams: {total_m3u8_streams}")
          print(f"  🎬 Total VOD Files: {total_vod_files}")
          print(f"  📡 Total TS Streams: {total_ts_streams}")
          print(f"  🔗 Total Other Streams: {total_other_streams}")
          print(f"📊 Results: {working_streams} working, {total_failures} failed, {skipped_streams} skipped")
          
          # Validate results before proceeding
          if total_streams == 0:
              print("❌ No streams found to process!")
              import sys
              sys.exit(1)
          
          print("✅ Stream checking completed successfully")
          
          # Generate enhanced report
          print("📝 Generating report...")
          
          try:
              # Calculate percentages safely
              checked_percentage = (total_checked/total_streams*100) if total_streams > 0 else 0
              failure_percentage = (total_failures/total_checked*100) if total_checked > 0 else 0
              skipped_percentage = (skipped_streams/total_streams*100) if total_streams > 0 else 0
              m3u8_percentage = (total_m3u8_streams/total_streams*100) if total_streams > 0 else 0
              vod_percentage = (total_vod_files/total_streams*100) if total_streams > 0 else 0
              ts_percentage = (total_ts_streams/total_streams*100) if total_streams > 0 else 0
              other_percentage = (total_other_streams/total_streams*100) if total_streams > 0 else 0
              
              # Build report
              vod_config = '✅' if CHECK_VODS else '❌'
              ppv_config = '✅' if CHECK_PPV else '❌'
              
              # Calculate success rates by type
              type_success_rates = {}
              for stream_type in working_by_type.keys():
                  total_type = working_by_type[stream_type] + failed_by_type[stream_type]
                  if total_type > 0:
                      type_success_rates[stream_type] = (working_by_type[stream_type] / total_type * 100)
                  else:
                      type_success_rates[stream_type] = 0
              
              report = "# 📺 Enhanced M3U Stream Status Report\n\n"
              report += f"**Generated on:** {end_time.strftime('%Y-%m-%d %H:%M:%S')} UTC  \n"
              report += f"**Duration:** {duration.total_seconds():.1f} seconds  \n"
              report += "**Runner Location:** GitHub Actions (global infrastructure)  \n"
              report += f"**Configuration:** VODs: {vod_config}, PPV: {ppv_config}, Timeout: {TIMEOUT_SECONDS}s\n\n"
              
              report += "## 📊 Summary\n\n"
              report += "| Metric | Count | Percentage |\n"
              report += "|--------|-------|-----------|\n"
              report += f"| **Total Streams Found** | {total_streams} | 100% |\n"
              report += f"| **📺 M3U8 Streams** | {total_m3u8_streams} | {m3u8_percentage:.1f}% |\n"
              report += f"| **🎬 VOD Files** | {total_vod_files} | {vod_percentage:.1f}% |\n"
              report += f"| **📡 TS Streams** | {total_ts_streams} | {ts_percentage:.1f}% |\n"
              report += f"| **🔗 Other Streams** | {total_other_streams} | {other_percentage:.1f}% |\n"
              report += f"| **🔍 Checked Streams** | {total_checked} | {checked_percentage:.1f}% |\n"
              report += f"| **✅ Working Streams** | {working_streams} | {working_percentage:.1f}% |\n"
              report += f"| **❌ Failed Streams** | {total_failures} | {failure_percentage:.1f}% |\n"
              report += f"| **⭕ Skipped Streams** | {skipped_streams} | {skipped_percentage:.1f}% |\n\n"
              
              report += "## 📊 Stream Type Breakdown\n\n"
              report += "| Type | Working | Failed | Total Checked | Success Rate |\n"
              report += "|------|---------|--------|---------------|-------------|\n"
              
              for stream_type in ['M3U8', 'VOD', 'TS', 'RTMP', 'Other']:
                  working_count = working_by_type[stream_type]
                  failed_count = failed_by_type[stream_type]
                  total_type = working_count + failed_count
                  success_rate = type_success_rates[stream_type]
                  
                  if total_type > 0:
                      type_icon = {'M3U8': '📺', 'VOD': '🎬', 'TS': '📡', 'RTMP': '🔴', 'Other': '🔗'}[stream_type]
                      report += f"| **{type_icon} {stream_type}** | {working_count} | {failed_count} | {total_type} | {success_rate:.1f}% |\n"
              
              report += "\n## 📁 Files Processed\n\n"
              
              print("📝 Report header generated successfully")
              
          except Exception as e:
              print(f"❌ Error generating report header: {str(e)}")
              import traceback
              traceback.print_exc()
              import sys
              sys.exit(1)
          
          try:
              for m3u_file in m3u_files:
                  if os.path.exists(m3u_file):
                      file_streams = parse_m3u(m3u_file)
                      file_m3u8 = sum(1 for s in file_streams if classify_stream_type(s['url']) == 'M3U8')
                      file_vod = sum(1 for s in file_streams if classify_stream_type(s['url']) == 'VOD')
                      file_ts = sum(1 for s in file_streams if classify_stream_type(s['url']) == 'TS')
                      file_other = len(file_streams) - file_m3u8 - file_vod - file_ts
                      report += f"- `{m3u_file}`: {len(file_streams)} streams ({file_m3u8} M3U8, {file_vod} VOD, {file_ts} TS, {file_other} Other)\n"
              
              print("📁 Files section added")
              
          except Exception as e:
              print(f"❌ Error adding files section: {str(e)}")
              import traceback
              traceback.print_exc()
              import sys
              sys.exit(1)
          
          # Skipped streams section
          try:
              if skipped_streams > 0:
                  print("📝 Adding skipped streams section")
                  report += f"\n## ⭕ Skipped Streams ({skipped_streams} total)\n\n"
                  
                  if skipped_categories['vods'] and not CHECK_VODS:
                      print(f"📝 Adding VOD summary")
                      
                      # Count VODs by group
                      vod_groups = {}
                      for item in skipped_categories['vods']:
                          group = item.get('group', 'No Group')
                          vod_groups[group] = vod_groups.get(group, 0) + 1
                      
                      report += f"### 🎬 VOD Files ({len(skipped_categories['vods'])} skipped)\n"
                      report += "*Enable \"Check VODs\" in workflow dispatch to test these*\n\n"
                      report += "| Group | Count |\n"
                      report += "|-------|---------|\n"
                      
                      for group, count in sorted(vod_groups.items()):
                          group_safe = str(group).replace('|', '\\|')
                          report += f"| {group_safe} | {count} |\n"
                      report += "\n"
                  
                  if skipped_categories['ppv'] and not CHECK_PPV:
                      print(f"📝 Adding PPV summary")
                      
                      # Count PPV by group
                      ppv_groups = {}
                      for item in skipped_categories['ppv']:
                          group = item.get('group', 'No Group')
                          ppv_groups[group] = ppv_groups.get(group, 0) + 1
                      
                      report += f"### 🥊 PPV/Event Channels ({len(skipped_categories['ppv'])} skipped)\n"
                      report += "*Enable \"Check PPV\" in workflow dispatch to test these*\n\n"
                      report += "| Group | Count |\n"
                      report += "|-------|---------|\n"
                      
                      for group, count in sorted(ppv_groups.items()):
                          group_safe = str(group).replace('|', '\\|')
                          report += f"| {group_safe} | {count} |\n"
                      report += "\n"
              
              print("📝 Skipped streams section completed")
              
          except Exception as e:
              print(f"❌ Error generating skipped streams section: {str(e)}")
              import traceback
              traceback.print_exc()
              # Continue anyway - this is not critical
              report += "\n*Error generating skipped streams details*\n"
          
          # Enhanced failure analysis
          try:
              if total_failures > 0:
                  print(f"📝 Adding failure analysis for {total_failures} failures")
                  failure_categories = {
                      'access_denied': ('🚫 Access Denied', 'Geo-blocked or authentication required'),
                      'timeout': ('⏱️ Connection Timeouts', 'Server slow/overloaded or PPV preparing'),
                      'dns_error': ('🌐 DNS Failures', 'Domain name resolution failed'),
                      'not_found': ('❓ Not Found (404)', 'Stream URL no longer exists'),
                      'server_error': ('💥 Server Errors (5xx)', 'Server-side technical issues'),
                      'connection_error': ('🔗 Connection Errors', 'Network connectivity problems'),
                      'stream_error': ('📺 Stream Errors', 'Stream exists but unreadable'),
                      'rate_limited': ('🚫 Rate Limited', 'Too many requests'),
                      'http_error': ('🌐 HTTP Errors', 'Other HTTP status codes'),
                      'unknown_error': ('❓ Unknown Errors', 'Unexpected errors')
                  }
                  
                  report += f"\n## 📋 Failure Analysis ({total_failures} total failures)\n\n"
                  
                  for category, failures in categorized_failures.items():
                      if failures:
                          title, description = failure_categories.get(category, (f'❓ {category}', 'Unknown error type'))
                          print(f"📝 Adding {len(failures)} failures for {category}")
                          report += f"### {title} ({len(failures)} streams)\n"
                          report += f"*{description}*\n\n"
                          report += "| Channel | Group | Type | Error | Code | File |\n"
                          report += "|---------|-------|------|-------|------|---------|\n"
                          
                          for stream in failures:
                              try:
                                  name = str(stream.get('name', 'Unknown'))[:30].replace('|', '\\|')
                                  group = str(stream.get('group', 'No Group'))[:20].replace('|', '\\|')
                                  stream_type = str(stream.get('type', 'Live'))[:8]
                                  error = str(stream.get('error', 'Unknown'))[:40].replace('|', '\\|')
                                  code = str(stream.get('code', 'N/A'))
                                  file_name = str(stream.get('file', 'Unknown')).replace('|', '\\|')
                                  
                                  report += f"| {name} | {group} | {stream_type} | {error} | {code} | {file_name} |\n"
                              except Exception as e:
                                  print(f"⚠️ Error adding failure entry: {str(e)}")
                                  continue
                          
                          report += "\n"
              
              else:
                  print("📝 No failures to report - adding success message")
                  report += "\n## 🎉 All Checked Streams Working!\n\n"
                  report += "All tested streams are currently accessible from GitHub's infrastructure.\n"
              
              print("📝 Failure analysis section completed")
              
          except Exception as e:
              print(f"❌ Error generating failure analysis: {str(e)}")
              import traceback
              traceback.print_exc()
              # Add a simple fallback
              report += f"\n## 📋 Failure Analysis\n\n*Error generating detailed failure analysis. {total_failures} streams failed.*\n"
          
          # Add final sections
          try:
              print("📝 Adding final configuration and notes sections")
              vod_status = 'Enabled' if CHECK_VODS else 'Disabled'
              ppv_status = 'Enabled' if CHECK_PPV else 'Disabled'
              vod_tested = 'were' if CHECK_VODS else 'were not'
              ppv_tested = 'were' if CHECK_PPV else 'were not'
              
              report += f"\n## 📋 Configuration Notes\n\n"
              report += f"- **VOD Checking:** {vod_status} - VOD files with various formats {vod_tested} tested\n"
              report += f"- **PPV/Event Checking:** {ppv_status} - UK EVENTS & USA EVENTS groups {ppv_tested} tested\n"
              report += f"- **Timeout:** {TIMEOUT_SECONDS} seconds per stream (PPV channels get 2x timeout)\n"
              report += "- **VOD Detection:** Enhanced to detect #.mkv, .mkv/, .mkv?, /movie/, /film/, /vod/ patterns\n"
              report += "- **M3U8 Detection:** Matches URLs containing .m3u8 anywhere (handles tokens/parameters)\n"
              report += "- **TS Detection:** Identifies .ts stream URLs as separate category\n"
              report += "- **Event Groups:** Automatically detects \"UK EVENTS\", \"USA EVENTS\", and similar groups\n\n"
              
              report += "## 📈 Geographic & Technical Notes\n\n"
              report += "- Tests run from **GitHub Actions** global infrastructure\n"
              report += "- \"Access Denied\" (403) errors typically indicate geo-restrictions\n"
              report += "- PPV channels may be offline between events (normal behavior)\n"
              report += "- VOD files are static content and should be consistently available\n"
              report += "- M3U8 streams are adaptive bitrate live streams\n"
              report += "- TS streams are transport stream format (often live TV)\n"
              report += "- Timeout errors may indicate server overload or preparation time\n"
              report += "- DNS errors suggest the streaming service domain is down\n\n"
              
              report += "## 🔧 Technical Details\n\n"
              report += "- **User-Agent:** Chrome 120 simulation for maximum compatibility\n"
              report += "- **Method:** HEAD for direct video files, GET with stream verification for live content\n"
              report += "- **VOD Detection:** Enhanced patterns including hash (#), slash (/), and query (?) separators\n"
              report += "- **M3U8 Detection:** Identifies adaptive streaming URLs (.m3u8) with token support\n"
              report += "- **TS Detection:** Recognizes transport stream URLs (.ts)\n"
              report += "- **Headers:** Enhanced with security headers and proper content type\n"
              report += "- **Rate Limiting:** Dynamic delays based on success rate\n"
              report += "- **Retry Logic:** Single attempt per stream to avoid overwhelming servers\n\n"
              
              report += "## 🎛️ Manual Testing Options\n\n"
              report += "To test specific content types:\n"
              report += "1. Go to **Actions** → **Check M3U Streams** → **Run workflow**\n"
              report += "2. Toggle **Check VODs** to test video-on-demand content\n"
              report += "3. Toggle **Check PPV** to test Pay-Per-View channels\n"
              report += "4. Adjust **Timeout** for slower connections\n\n"
              
              report += "---\n"
              report += f"*Last updated: {end_time.strftime('%Y-%m-%d %H:%M:%S')} UTC*\n"
              report += "*Report generated automatically by Enhanced GitHub Actions*\n"
              
              print("📝 Report generation completed successfully")
              
          except Exception as e:
              print(f"❌ Error adding final sections: {str(e)}")
              import traceback
              traceback.print_exc()
              # Add minimal footer
              report += f"\n---\n*Last updated: {end_time.strftime('%Y-%m-%d %H:%M:%S')} UTC*\n"
          
          # Write report
          print("💾 Writing report to file...")
          try:
              with open('report.md', 'w', encoding='utf-8') as f:
                  f.write(report)
              print("📊 Enhanced report generated successfully!")
              print(f"📈 Final Summary: {working_streams}/{total_checked} streams working ({working_percentage:.1f}%), {skipped_streams} skipped")
              
              # Define the icon mapping outside the f-string to avoid syntax issues
              type_icons = {'M3U8': '📺', 'VOD': '🎬', 'TS': '📡', 'RTMP': '🔴', 'Other': '🔗'}
              
              for stream_type in ['M3U8', 'VOD', 'TS', 'RTMP', 'Other']:
                  working_count = working_by_type[stream_type]
                  failed_count = failed_by_type[stream_type]
                  if working_count > 0 or failed_count > 0:
                      icon = type_icons[stream_type]
                      print(f"{icon} {stream_type}: {working_count} working, {failed_count} failed")
              
              # Verify file was written
              if os.path.exists('report.md'):
                  file_size = os.path.getsize('report.md')
                  print(f"✅ Report file created: {file_size} bytes")
              else:
                  print("❌ Report file was not created!")
                  import sys
                  sys.exit(1)
              
          except Exception as e:
              print(f"❌ Error writing report: {str(e)}")
              import traceback
              traceback.print_exc()
              import sys
              sys.exit(1)
          
          print("🎉 Script completed successfully!")
          EOF
          
          # Verify Python script succeeded
          if [ $? -eq 0 ]; then
            echo "✅ Python script completed successfully"
          else
            echo "❌ Python script failed with exit code $?"
            exit 1
          fi
          
          # Double-check report file exists
          if [ -f "report.md" ]; then
            echo "✅ Report file confirmed"
            echo "📊 Report size: $(wc -c < report.md) bytes"
            echo "📋 First few lines of report:"
            head -5 report.md
          else
            echo "❌ Report file missing after Python execution!"
            ls -la
            exit 1
          fi
        
      - name: Commit and push report
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "github-actions[bot]"
          
          # Check if report was generated
          if [[ -f "report.md" ]]; then
            echo "✅ Report file found"
            ls -la report.md
          else
            echo "❌ Report file not found!"
            ls -la
            exit 1
          fi
          
          git add report.md
          if git diff --staged --quiet; then
            echo "📝 No changes to commit"
          else
            # Enhanced commit message with configuration info
            COMMIT_MSG="📊 Stream report"
            if [[ "${CHECK_VODS:-false}" == "true" ]]; then
              COMMIT_MSG="$COMMIT_MSG +VODs"
            fi
            if [[ "${CHECK_PPV:-false}" == "true" ]]; then
              COMMIT_MSG="$COMMIT_MSG +PPV" 
            fi
            COMMIT_MSG="$COMMIT_MSG - $(date -u '+%Y-%m-%d %H:%M UTC')"
            
            echo "💾 Committing: $COMMIT_MSG"
            git commit -m "$COMMIT_MSG"
            git push
            echo "🚀 Report pushed successfully"
          fi
