name: Check M3U Streams with Hot-Swap

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'  # Runs every 6 hours

permissions:
  contents: write

jobs:
  check-streams:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests m3u8

      - name: Check Streams and Hot-Swap
        run: |
          python - << 'EOF'
          import requests
          import os
          from datetime import datetime
          import re
          import time
          import json
          from urllib.parse import urlparse
          
          # Backup source URLs in priority order (higher priority first)
          BACKUP_SOURCES = [
              {
                  'url': 'https://github.com/Jehovah-witnesses-here/Stream-collection-/raw/refs/heads/main/moj.m3u',
                  'name': 'moj',
                  'priority': 1
              },
              {
                  'url': 'https://github.com/Jehovah-witnesses-here/Stream-collection-/raw/refs/heads/main/dlive.m3u',
                  'name': 'dlive',
                  'priority': 2
              }
          ]
          
          def download_backup_sources():
              """Download backup M3U files and parse them (without testing URLs)"""
              backup_streams = {}
              
              # Sort backup sources by priority (ascending - lower number = higher priority)
              sorted_sources = sorted(BACKUP_SOURCES, key=lambda x: x['priority'])
              
              for source in sorted_sources:
                  try:
                      print(f"Downloading backup source '{source['name']}' (Priority {source['priority']}): {source['url']}")
                      response = requests.get(source['url'], timeout=30)
                      response.raise_for_status()
                      
                      # Parse the downloaded M3U content
                      lines = response.text.strip().split('\n')
                      
                      for j in range(len(lines)):
                          line = lines[j].strip()
                          if line.startswith('#EXTINF'):
                              try:
                                  # Extract channel name (after last comma)
                                  name_part = line.split(',')[-1].strip()
                                  name = name_part if name_part else "Unknown Channel"
                                  
                                  # Get URL from next line
                                  if j + 1 < len(lines):
                                      stream_url = lines[j + 1].strip()
                                      if stream_url and not stream_url.startswith('#') and ('http' in stream_url or 'rtmp' in stream_url):
                                          # Store alternatives with priority order
                                          if name not in backup_streams:
                                              backup_streams[name] = []
                                          backup_streams[name].append({
                                              'url': stream_url,
                                              'source': source['name'],
                                              'priority': source['priority']
                                          })
                              except Exception as e:
                                  print(f"Error parsing backup line {j}: {str(e)}")
                                  continue
                                  
                  except Exception as e:
                      print(f"Error downloading backup source {source['url']}: {str(e)}")
              
              # Sort backup streams by priority within each channel
              for channel_name in backup_streams:
                  backup_streams[channel_name].sort(key=lambda x: x['priority'])
              
              print(f"Downloaded {len(backup_streams)} unique channel names from backup sources")
              return backup_streams
          
          def check_stream(url, timeout=15):
              """Check if a stream URL is accessible and categorize failures"""
              try:
                  # Handle different types of URLs
                  headers = {
                      'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                      'Accept': '*/*',
                      'Accept-Language': 'en-US,en;q=0.9',
                      'Accept-Encoding': 'gzip, deflate',
                      'Connection': 'keep-alive',
                      'Referer': 'https://github.com/'
                  }
                  
                  # First try HEAD request
                  try:
                      response = requests.head(url, timeout=timeout, headers=headers, allow_redirects=True)
                      if response.status_code < 400:
                          return {"status": "working", "code": response.status_code, "error": None}
                  except:
                      pass
                  
                  # If HEAD fails, try GET with stream
                  response = requests.get(url, timeout=timeout, headers=headers, stream=True, allow_redirects=True)
                  
                  if response.status_code < 400:
                      # Try to read a small chunk to verify it's actually streaming
                      try:
                          next(response.iter_content(chunk_size=1024), None)
                          return {"status": "working", "code": response.status_code, "error": None}
                      except:
                          return {"status": "stream_error", "code": response.status_code, "error": "Stream not readable"}
                  else:
                      # Categorize HTTP errors
                      if response.status_code == 403:
                          return {"status": "access_denied", "code": 403, "error": "Access denied (possibly geo-blocked)"}
                      elif response.status_code == 404:
                          return {"status": "not_found", "code": 404, "error": "Stream not found"}
                      elif response.status_code in [500, 502, 503, 504]:
                          return {"status": "server_error", "code": response.status_code, "error": "Server error"}
                      else:
                          return {"status": "http_error", "code": response.status_code, "error": f"HTTP {response.status_code}"}
                          
              except requests.exceptions.Timeout:
                  return {"status": "timeout", "code": None, "error": "Connection timeout"}
              except requests.exceptions.ConnectionError as e:
                  error_str = str(e)
                  if "Name or service not known" in error_str or "Failed to resolve" in error_str:
                      return {"status": "dns_error", "code": None, "error": "DNS resolution failed"}
                  elif "Connection refused" in error_str:
                      return {"status": "connection_refused", "code": None, "error": "Connection refused"}
                  else:
                      return {"status": "connection_error", "code": None, "error": "Connection error"}
              except Exception as e:
                  return {"status": "unknown_error", "code": None, "error": str(e)[:100]}
          
          def find_backup_stream(channel_name, backup_streams, used_urls=set()):
              """Find a working backup stream for a given channel name with priority order"""
              attempt_log = {
                  'channel_name': channel_name,
                  'exact_matches_found': 0,
                  'fuzzy_matches_found': 0,
                  'candidates_tested': [],
                  'success': False,
                  'final_source': None
              }
              
              def test_backup_candidates(candidates, match_type):
                  """Test backup candidates in priority order"""
                  # Sort candidates by priority (lower number = higher priority)
                  sorted_candidates = sorted(candidates, key=lambda x: x['priority'])
                  
                  for backup in sorted_candidates:
                      if backup['url'] not in used_urls:
                          candidate_info = {
                              'source': backup['source'],
                              'priority': backup['priority'],
                              'url': backup['url'][:80] + '...' if len(backup['url']) > 80 else backup['url'],
                              'match_type': match_type,
                              'matched_name': backup.get('matched_name', channel_name)
                          }
                          
                          print(f"    Testing {backup['source']} (priority {backup['priority']}): {backup['url'][:60]}...")
                          result = check_stream(backup['url'], timeout=10)
                          
                          candidate_info['test_result'] = result['status']
                          candidate_info['error'] = result['error']
                          attempt_log['candidates_tested'].append(candidate_info)
                          
                          if result['status'] == 'working':
                              used_urls.add(backup['url'])
                              attempt_log['success'] = True
                              attempt_log['final_source'] = backup['source']
                              return backup['url'], backup['source']
                          else:
                              print(f"    âŒ Failed: {result['error']}")
                  return None, None
              
              # Try exact match first
              if channel_name in backup_streams:
                  attempt_log['exact_matches_found'] = len(backup_streams[channel_name])
                  print(f"  Found {attempt_log['exact_matches_found']} exact match candidates for '{channel_name}'")
                  backup_url, backup_source = test_backup_candidates(backup_streams[channel_name], 'exact')
                  if backup_url:
                      return backup_url, backup_source, attempt_log
              
              # Try partial matches (case-insensitive)
              channel_lower = channel_name.lower()
              potential_matches = []
              
              for backup_name, backups in backup_streams.items():
                  backup_lower = backup_name.lower()
                  # Check if names are similar (contains or partial match)
                  if (channel_lower in backup_lower or backup_lower in channel_lower or
                      any(word in backup_lower for word in channel_lower.split() if len(word) > 3)):
                      
                      # Add all candidates from this match with the matched name info
                      for backup in backups:
                          potential_matches.append({
                              'url': backup['url'],
                              'source': f"{backup['source']} (matched: {backup_name})",
                              'priority': backup['priority'],
                              'matched_name': backup_name
                          })
              
              if potential_matches:
                  attempt_log['fuzzy_matches_found'] = len(potential_matches)
                  print(f"  Found {len(potential_matches)} fuzzy match candidates")
                  backup_url, backup_source = test_backup_candidates(potential_matches, 'fuzzy')
                  if backup_url:
                      return backup_url, backup_source, attempt_log
              
              return None, None, attempt_log
          
          def parse_m3u(file_path):
              """Parse M3U file and extract stream information with line numbers"""
              if not os.path.exists(file_path):
                  print(f"File not found: {file_path}")
                  return [], []
                  
              streams = []
              all_lines = []
              
              try:
                  with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                      all_lines = f.readlines()
              except Exception as e:
                  print(f"Error reading {file_path}: {str(e)}")
                  return [], []
                  
              for i in range(len(all_lines)):
                  line = all_lines[i].strip()
                  if line.startswith('#EXTINF'):
                      try:
                          # Extract group-title if present
                          group_match = re.search(r'group-title="([^"]*)"', line)
                          group = group_match.group(1) if group_match else "No Group"
                          
                          # Extract channel name (after last comma)
                          name_part = line.split(',')[-1].strip()
                          name = name_part if name_part else "Unknown Channel"
                          
                          # Get URL from next line
                          if i + 1 < len(all_lines):
                              url = all_lines[i + 1].strip()
                              if url and not url.startswith('#') and ('http' in url or 'rtmp' in url):
                                  streams.append({
                                      'name': name,
                                      'url': url,
                                      'group': group,
                                      'extinf_line': i,
                                      'url_line': i + 1
                                  })
                      except Exception as e:
                          print(f"Error parsing line {i}: {str(e)}")
                          continue
              
              return streams, all_lines
          
          def write_m3u(file_path, lines):
              """Write lines back to M3U file"""
              try:
                  with open(file_path, 'w', encoding='utf-8') as f:
                      f.writelines(lines)
                  return True
              except Exception as e:
                  print(f"Error writing {file_path}: {str(e)}")
                  return False
          
          # Initialize counters and lists
          total_streams = 0
          working_streams = 0
          swapped_streams = 0
          categorized_failures = {
              'access_denied': [],
              'timeout': [],
              'dns_error': [],
              'not_found': [],
              'server_error': [],
              'connection_error': [],
              'stream_error': [],
              'http_error': [],
              'unknown_error': []
          }
          checked_streams = 0
          swap_log = []
          swap_attempts_log = []  # Track all swap attempts, not just successful ones
          
          # Download backup streams
          print("Downloading backup stream sources...")
          backup_streams = download_backup_sources()
          used_backup_urls = set()
          
          # Only process channel playlist for hot-swapping
          target_file = 'channel playlist.m3u'
          m3u_files = [
              'vod playlist.m3u',
              'channel playlist.m3u'
          ]
          
          print("Starting stream check with hot-swap capability...")
          
          for m3u_file in m3u_files:
              print(f"Processing {m3u_file}...")
              
              try:
                  streams, file_lines = parse_m3u(m3u_file)
                  file_total = len(streams)
                  total_streams += file_total
                  file_working = 0
                  file_swapped = 0
                  
                  print(f"Found {file_total} streams in {m3u_file}")
                  
                  for i, stream in enumerate(streams):
                      checked_streams += 1
                      print(f"Checking stream {checked_streams}/{total_streams}: {stream['name'][:50]}...")
                      
                      result = check_stream(stream['url'])
                      
                      if result['status'] == 'working':
                          working_streams += 1
                          file_working += 1
                      else:
                          # Try to find a backup stream (only for channel playlist)
                          if m3u_file == target_file and backup_streams:
                              print(f"  Stream failed, searching for backup: {stream['name']}")
                              backup_result = find_backup_stream(stream['name'], backup_streams, used_backup_urls)
                              
                              if len(backup_result) == 3:  # Successful call with attempt log
                                  backup_url, backup_source, attempt_log = backup_result
                                  swap_attempts_log.append(attempt_log)
                                  
                                  if backup_url:
                                      # Replace the URL in the file lines
                                      old_url = stream['url']
                                      file_lines[stream['url_line']] = backup_url + '\n'
                                      
                                      # Log the swap
                                      swap_info = {
                                          'name': stream['name'],
                                          'group': stream['group'],
                                          'old_url': old_url[:100] + '...' if len(old_url) > 100 else old_url,
                                          'new_url': backup_url[:100] + '...' if len(backup_url) > 100 else backup_url,
                                          'backup_source': backup_source,
                                          'original_error': result['error']
                                      }
                                      swap_log.append(swap_info)
                                      
                                      swapped_streams += 1
                                      file_swapped += 1
                                      working_streams += 1
                                      file_working += 1
                                      
                                      print(f"  âœ… Swapped to backup from {backup_source}")
                                  else:
                                      print(f"  âŒ No working backup found")
                                      # Still categorize the failure
                                      failure_info = {
                                          'name': stream['name'],
                                          'group': stream['group'],
                                          'url': stream['url'][:100] + '...' if len(stream['url']) > 100 else stream['url'],
                                          'file': m3u_file,
                                          'error': result['error'],
                                          'code': result['code']
                                      }
                                      
                                      if result['status'] in categorized_failures:
                                          categorized_failures[result['status']].append(failure_info)
                                      else:
                                          categorized_failures['unknown_error'].append(failure_info)
                              else:
                                  print(f"  âŒ Error in backup search")
                                  # Handle the case where find_backup_stream failed
                                  failure_info = {
                                      'name': stream['name'],
                                      'group': stream['group'],
                                      'url': stream['url'][:100] + '...' if len(stream['url']) > 100 else stream['url'],
                                      'file': m3u_file,
                                      'error': result['error'],
                                      'code': result['code']
                                  }
                                  
                                  if result['status'] in categorized_failures:
                                      categorized_failures[result['status']].append(failure_info)
                                  else:
                                      categorized_failures['unknown_error'].append(failure_info)
                          else:
                              # Categorize the failure (for non-channel playlist or when no backups available)
                              failure_info = {
                                  'name': stream['name'],
                                  'group': stream['group'],
                                  'url': stream['url'][:100] + '...' if len(stream['url']) > 100 else stream['url'],
                                  'file': m3u_file,
                                  'error': result['error'],
                                  'code': result['code']
                              }
                              
                              if result['status'] in categorized_failures:
                                  categorized_failures[result['status']].append(failure_info)
                              else:
                                  categorized_failures['unknown_error'].append(failure_info)
                      
                      # Small delay to avoid overwhelming servers
                      time.sleep(0.1)
                  
                  # Write back the modified file if there were swaps
                  if m3u_file == target_file and file_swapped > 0:
                      if write_m3u(m3u_file, file_lines):
                          print(f"âœ… Updated {m3u_file} with {file_swapped} hot-swaps")
                      else:
                          print(f"âŒ Failed to write updated {m3u_file}")
                  
                  print(f"File {m3u_file}: {file_working}/{file_total} working streams ({file_swapped} swapped)")
                  
              except Exception as e:
                  print(f"Error processing {m3u_file}: {str(e)}")
          
          # Calculate totals
          total_failures = sum(len(failures) for failures in categorized_failures.values())
          working_percentage = (working_streams / total_streams * 100) if total_streams > 0 else 0
          
          # Generate report
          report = f"""# ðŸ“º M3U Stream Status Report with Hot-Swap
          
          **Generated on:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC
          **GitHub Actions Runner Location:** GitHub's infrastructure (global)
          
          ## ðŸ“Š Summary
          
          | Metric | Count | Percentage |
          |--------|-------|------------|
          | **Total Streams** | {total_streams} | 100% |
          | **âœ… Working Streams** | {working_streams} | {working_percentage:.1f}% |
          | **ðŸ”„ Hot-Swapped Streams** | {swapped_streams} | {(swapped_streams/total_streams*100):.1f}% |
          | **âŒ Failed Streams** | {total_failures} | {((total_failures)/total_streams*100):.1f}% |
          
          ## ðŸ“ Files Processed
          
          """
          
          for m3u_file in m3u_files:
              if os.path.exists(m3u_file):
                  file_streams, _ = parse_m3u(m3u_file)
                  hot_swap_note = " **(Hot-swap enabled)**" if m3u_file == target_file else ""
                  report += f"- `{m3u_file}`: {len(file_streams)} streams{hot_swap_note}\n"
              else:
                  report += f"- `{m3u_file}`: **File not found**\n"
          
          # Hot-swap summary
          if swap_log:
              report += f"""
          ## ðŸ”„ Hot-Swap Summary ({len(swap_log)} streams replaced)
          
          The following failing streams were automatically replaced with working alternatives:
          
          | Channel Name | Group | Backup Source | Original Error |
          |-------------|-------|---------------|----------------|
          """
              
              for swap in swap_log:
                  name = swap['name'].replace('|', '\\|').replace('\n', ' ').strip()
                  group = swap['group'].replace('|', '\\|').replace('\n', ' ').strip()
                  backup_source = swap['backup_source'].replace('|', '\\|')
                  error = swap['original_error'].replace('|', '\\|') if swap['original_error'] else 'Unknown'
                  
                  report += f"| {name} | {group} | {backup_source} | {error} |\n"
              
              report += f"""
          ### ðŸ“‹ Backup Sources Used (Priority Order)
          
          **Priority System:** Original playlist â†’ moj â†’ dlive
          
          """
              for source in sorted(BACKUP_SOURCES, key=lambda x: x['priority']):
                  report += f"- **{source['name']}** (Priority {source['priority']}): {source['url']}\n"
          
          # Hot-swap attempts details (for failed channels)
          failed_channel_attempts = [attempt for attempt in swap_attempts_log if not attempt['success']]
          if failed_channel_attempts:
              report += f"""
          ## ðŸ” Hot-Swap Attempt Details ({len(failed_channel_attempts)} channels)
          
          *Detailed breakdown of what was tried for channels that couldn't be fixed:*
          
          """
              
              for attempt in failed_channel_attempts:
                  report += f"""### {attempt['channel_name']}
          
          - **Exact matches found:** {attempt['exact_matches_found']}
          - **Fuzzy matches found:** {attempt['fuzzy_matches_found']}
          - **Total candidates tested:** {len(attempt['candidates_tested'])}
          
          """
                  
                  if attempt['candidates_tested']:
                      report += """| Source | Priority | Match Type | Result | Error |
          |--------|----------|------------|--------|-------|
          """
                      for candidate in attempt['candidates_tested']:
                          source = candidate['source'].replace('|', '\\|')
                          match_type = candidate['match_type']
                          result = candidate['test_result']
                          error = candidate.get('error', 'N/A') or 'N/A'
                          error = error.replace('|', '\\|')
                          
                          if candidate['match_type'] == 'fuzzy':
                              matched_name = candidate.get('matched_name', 'Unknown')
                              source += f" â†’ {matched_name}"
                          
                          report += f"| {source} | {candidate['priority']} | {match_type} | {result} | {error} |\n"
                  else:
                      report += "*No backup streams found for this channel name.*\n"
                  
                  report += "\n"
          elif len(swap_attempts_log) > 0:
              # All attempts were successful
              report += f"""
          ## âœ… All Hot-Swap Attempts Successful
          
          {len(swap_attempts_log)} channels were successfully replaced with backup streams on the first suitable match found.
          """
          
          # Failure categories with explanations
          failure_categories = {
              'access_denied': ('ðŸš« Access Denied', 'Likely geo-blocked or requires authentication'),
              'timeout': ('â±ï¸ Connection Timeouts', 'Server too slow to respond or overloaded'),
              'dns_error': ('ðŸŒ DNS Resolution Failures', 'Domain name cannot be resolved'),
              'not_found': ('â“ Not Found (404)', 'Stream URL no longer exists'),
              'server_error': ('ðŸ’¥ Server Errors (5xx)', 'Server-side issues'),
              'connection_error': ('ðŸ”— Connection Errors', 'Network connectivity issues'),
              'stream_error': ('ðŸ“º Stream Reading Errors', 'Stream exists but content unreadable'),
              'http_error': ('ðŸŒ Other HTTP Errors', 'Various HTTP status codes'),
              'unknown_error': ('â“ Unknown Errors', 'Unexpected errors')
          }
          
          if total_failures > 0:
              report += f"""
          ## ðŸ“‹ Remaining Failures ({total_failures} streams)
          
          *These streams failed and no working backup was found.*
          
          """
              
              for category, failures in categorized_failures.items():
                  if failures:
                      title, description = failure_categories[category]
                      report += f"""### {title} ({len(failures)} streams)
          *{description}*
          
          | Channel Name | Group | File | Error Details | Code |
          |-------------|-------|------|---------------|------|
          """
                      
                      for stream in failures:
                          # Escape special characters for markdown
                          name = stream['name'].replace('|', '\\|').replace('\n', ' ').strip()
                          group = stream['group'].replace('|', '\\|').replace('\n', ' ').strip()
                          file_name = stream['file'].replace('|', '\\|')
                          error = stream['error'].replace('|', '\\|') if stream['error'] else 'Unknown'
                          code = stream['code'] if stream['code'] else 'N/A'
                          
                          report += f"| {name} | {group} | {file_name} | {error} | {code} |\n"
                      
                      report += "\n"
          else:
              if swapped_streams == 0:
                  report += """
          ## ðŸŽ‰ All Streams Working!
          
          Congratulations! All streams are currently accessible from GitHub's infrastructure.
          """
              else:
                  report += f"""
          ## ðŸŽ‰ All Streams Now Working!
          
          Thanks to hot-swapping, all streams are now working! {swapped_streams} streams were automatically replaced with backup sources.
          """
          
          report += f"""
          ## ðŸ“ˆ Hot-Swap Technology
          
          - **Priority Order:** Original `{target_file}` â†’ moj â†’ dlive
          - **Target File:** `{target_file}` (only this file gets modified)
          - **Backup Sources:** {len(BACKUP_SOURCES)} external M3U files with priority system
          - **Testing Strategy:** Backup streams are only tested when needed (during swap attempts)
          - **Matching Strategy:** Exact name match first, then fuzzy matching
          - **Verification:** Each backup URL is tested in priority order before replacement
          - **Prevention:** Same backup URL won't be used twice
          
          ## ðŸ“ˆ Geographic Notes
          
          - Tests run from **GitHub Actions infrastructure** (multiple global locations)
          - "Access Denied" errors may indicate geo-restrictions
          - Hot-swap uses alternative sources that may have different geographic availability
          - DNS errors suggest the streaming service may be down entirely
          - Timeout errors often indicate server overload or slow response
          
          ## ðŸ“ Technical Details
          
          - **User-Agent:** Modern browser simulation for better compatibility
          - **Timeout:** 15 seconds per stream, 10 seconds for backup verification
          - **Method:** HEAD request first, then GET with stream verification
          - **Hot-Swap Logic:** Download backup sources â†’ Match channel names â†’ Test alternatives â†’ Replace URLs
          - **File Modification:** Only `{target_file}` is modified with working alternatives
          
          ---
          *Last updated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC*
          *Report generated automatically by GitHub Actions*
          *Hot-swap technology: Automatically maintaining stream availability*
          """
          
          # Write report to file
          try:
              with open('report.md', 'w', encoding='utf-8') as f:
                  f.write(report)
              print("Report generated successfully!")
          except Exception as e:
              print(f"Error writing report: {str(e)}")
          
          print(f"Final Summary: {working_streams}/{total_streams} streams working ({working_percentage:.1f}%)")
          print(f"Hot-swaps performed: {swapped_streams}")
          if swapped_streams > 0:
              print(f"âœ… Updated {target_file} with working alternatives")
          EOF
        
      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "github-actions[bot]"
          git add .
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            # Check if channel playlist was modified
            if git diff --staged --name-only | grep -q "channel playlist.m3u"; then
              git commit -m "ðŸ”„ Hot-swap: Updated failing streams with working alternatives - $(date -u '+%Y-%m-%d %H:%M UTC')"
            else
              git commit -m "ðŸ“Š Update stream status report - $(date -u '+%Y-%m-%d %H:%M UTC')"
            fi
            git push
          fi
