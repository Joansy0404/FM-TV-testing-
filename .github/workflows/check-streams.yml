name: Check M3U Streams

on:
  workflow_dispatch:
    inputs:
      check_vods:
        description: 'Check VOD files (.mkv, .mp4, .avi)'
        required: false
        default: false
        type: boolean
      check_ppv:
        description: 'Check PPV channels (may be offline)'
        required: false
        default: false
        type: boolean
      timeout_seconds:
        description: 'Timeout per stream (seconds)'
        required: false
        default: '10'
        type: string
  schedule:
    - cron: '0 */6 * * *'  # Runs every 6 hours (without VODs/PPV by default)

permissions:
  contents: write

jobs:
  check-streams:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests m3u8

      - name: Check Streams
        env:
          CHECK_VODS: ${{ github.event.inputs.check_vods || 'false' }}
          CHECK_PPV: ${{ github.event.inputs.check_ppv || 'false' }}
          TIMEOUT_SECONDS: ${{ github.event.inputs.timeout_seconds || '10' }}
        run: |
          python - << 'EOF'
          import requests
          import os
          from datetime import datetime, timezone
          import re
          import time
          import urllib.parse
          
          # Configuration from environment
          CHECK_VODS = os.getenv('CHECK_VODS', 'false').lower() == 'true'
          CHECK_PPV = os.getenv('CHECK_PPV', 'false').lower() == 'true'
          TIMEOUT_SECONDS = int(os.getenv('TIMEOUT_SECONDS', '10'))
          
          print(f"Configuration: VODs={CHECK_VODS}, PPV={CHECK_PPV}, Timeout={TIMEOUT_SECONDS}s")
          
          def is_vod_url(url):
              """Check if URL points to a VOD file"""
              vod_extensions = ['.mkv', '.mp4', '.avi', '.mov', '.wmv', '.flv', '.webm', '.m4v']
              parsed_url = urllib.parse.urlparse(url)
              path = parsed_url.path.lower()
              return any(path.endswith(ext) for ext in vod_extensions)
          
          def is_ppv_channel(name, group):
              """Check if channel is PPV (Pay-Per-View)"""
              ppv_indicators = ['ppv', 'pay per view', 'boxing', 'ufc', 'wwe', 'event']
              name_lower = name.lower()
              group_lower = group.lower()
              
              return (any(indicator in name_lower for indicator in ppv_indicators) or 
                      any(indicator in group_lower for indicator in ppv_indicators) or
                      'ppv' in group_lower or 'events' in group_lower)
          
          def should_skip_stream(stream):
              """Determine if stream should be skipped based on configuration"""
              if is_vod_url(stream['url']) and not CHECK_VODS:
                  return True, "VOD file (skipped)"
              
              if is_ppv_channel(stream['name'], stream['group']) and not CHECK_PPV:
                  return True, "PPV channel (skipped)"
              
              return False, None
          
          def check_stream(url, timeout=10, is_ppv=False):
              """Check if a stream URL is accessible and categorize failures"""
              try:
                  # Enhanced headers for better compatibility
                  headers = {
                      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                      'Accept': '*/*',
                      'Accept-Language': 'en-US,en;q=0.9',
                      'Accept-Encoding': 'gzip, deflate, br',
                      'Connection': 'keep-alive',
                      'Referer': 'https://github.com/',
                      'Sec-Fetch-Dest': 'video',
                      'Sec-Fetch-Mode': 'no-cors',
                      'Sec-Fetch-Site': 'cross-site'
                  }
                  
                  # Adjust timeout for PPV channels (they might be slower)
                  if is_ppv:
                      timeout = min(timeout * 2, 30)
                  
                  # For VOD files, try HEAD first as they're usually static
                  if is_vod_url(url):
                      try:
                          response = requests.head(url, timeout=timeout, headers=headers, allow_redirects=True)
                          if response.status_code < 400:
                              return {"status": "working", "code": response.status_code, "error": None, "type": "VOD"}
                      except:
                          pass
                  
                  # Try GET request with streaming
                  response = requests.get(url, timeout=timeout, headers=headers, stream=True, allow_redirects=True)
                  
                  if response.status_code < 400:
                      # For live streams, try to read a small chunk
                      if not is_vod_url(url):
                          try:
                              chunk = next(response.iter_content(chunk_size=1024), None)
                              if chunk:
                                  stream_type = "PPV" if is_ppv else "Live Stream"
                                  return {"status": "working", "code": response.status_code, "error": None, "type": stream_type}
                              else:
                                  return {"status": "stream_error", "code": response.status_code, "error": "Empty stream response"}
                          except:
                              return {"status": "stream_error", "code": response.status_code, "error": "Stream not readable"}
                      else:
                          return {"status": "working", "code": response.status_code, "error": None, "type": "VOD"}
                  else:
                      # Enhanced error categorization
                      if response.status_code == 403:
                          return {"status": "access_denied", "code": 403, "error": "Access denied (geo-blocked/auth required)"}
                      elif response.status_code == 404:
                          error_msg = "Stream not found"
                          if is_ppv:
                              error_msg += " (PPV may be offline)"
                          return {"status": "not_found", "code": 404, "error": error_msg}
                      elif response.status_code in [500, 502, 503, 504]:
                          return {"status": "server_error", "code": response.status_code, "error": f"Server error ({response.status_code})"}
                      elif response.status_code == 429:
                          return {"status": "rate_limited", "code": 429, "error": "Rate limited"}
                      else:
                          return {"status": "http_error", "code": response.status_code, "error": f"HTTP {response.status_code}"}
                          
              except requests.exceptions.Timeout:
                  error_msg = f"Timeout after {timeout}s"
                  if is_ppv:
                      error_msg += " (PPV may be preparing)"
                  return {"status": "timeout", "code": None, "error": error_msg}
              except requests.exceptions.ConnectionError as e:
                  error_str = str(e)
                  if "Name or service not known" in error_str or "Failed to resolve" in error_str:
                      return {"status": "dns_error", "code": None, "error": "DNS resolution failed"}
                  elif "Connection refused" in error_str:
                      return {"status": "connection_refused", "code": None, "error": "Connection refused"}
                  else:
                      return {"status": "connection_error", "code": None, "error": "Network error"}
              except Exception as e:
                  return {"status": "unknown_error", "code": None, "error": str(e)[:100]}
          
          def parse_m3u(file_path):
              """Parse M3U file and extract stream information"""
              if not os.path.exists(file_path):
                  print(f"File not found: {file_path}")
                  return []
                  
              streams = []
              
              try:
                  with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                      lines = f.readlines()
              except Exception as e:
                  print(f"Error reading {file_path}: {str(e)}")
                  return []
                  
              for i in range(len(lines)):
                  line = lines[i].strip()
                  if line.startswith('#EXTINF'):
                      try:
                          # Extract group-title if present
                          group_match = re.search(r'group-title="([^"]*)"', line)
                          group = group_match.group(1) if group_match else "No Group"
                          
                          # Extract channel name (after last comma)
                          name_part = line.split(',')[-1].strip()
                          name = name_part if name_part else "Unknown Channel"
                          
                          # Get URL from next line
                          if i + 1 < len(lines):
                              url = lines[i + 1].strip()
                              if url and not url.startswith('#') and ('http' in url or 'rtmp' in url):
                                  streams.append({
                                      'name': name,
                                      'url': url,
                                      'group': group
                                  })
                      except Exception as e:
                          print(f"Error parsing line {i}: {str(e)}")
                          continue
              
              return streams
          
          # Initialize counters
          total_streams = 0
          checked_streams = 0
          working_streams = 0
          skipped_streams = 0
          
          # Enhanced failure categorization
          categorized_failures = {
              'access_denied': [],
              'timeout': [],
              'dns_error': [],
              'not_found': [],
              'server_error': [],
              'connection_error': [],
              'stream_error': [],
              'http_error': [],
              'rate_limited': [],
              'unknown_error': []
          }
          
          skipped_categories = {
              'vods': [],
              'ppv': []
          }
          
          # M3U files to process
          m3u_files = [
              'channel playlist.m3u'
          ]
          
          print("üöÄ Starting enhanced stream check...")
          start_time = datetime.now(timezone.utc)
          
          for m3u_file in m3u_files:
              print(f"üìÅ Processing {m3u_file}...")
              
              try:
                  streams = parse_m3u(m3u_file)
                  file_total = len(streams)
                  total_streams += file_total
                  file_working = 0
                  file_skipped = 0
                  
                  print(f"Found {file_total} streams in {m3u_file}")
                  
                  for i, stream in enumerate(streams):
                      # Check if stream should be skipped
                      should_skip, skip_reason = should_skip_stream(stream)
                      
                      if should_skip:
                          skipped_streams += 1
                          file_skipped += 1
                          
                          # Categorize skipped streams
                          if "VOD" in skip_reason:
                              skipped_categories['vods'].append({
                                  'name': stream['name'],
                                  'group': stream['group'],
                                  'file': m3u_file
                              })
                          elif "PPV" in skip_reason:
                              skipped_categories['ppv'].append({
                                  'name': stream['name'],
                                  'group': stream['group'],
                                  'file': m3u_file
                              })
                          
                          if i % 50 == 0:  # Progress update
                              print(f"Progress: {i+1}/{file_total} - Skipped: {stream['name'][:40]}...")
                          continue
                      
                      checked_streams += 1
                      print(f"üîç Checking {checked_streams}/{total_streams-skipped_streams}: {stream['name'][:40]}...")
                      
                      # Determine if this is a PPV channel for special handling
                      is_ppv = is_ppv_channel(stream['name'], stream['group'])
                      
                      result = check_stream(stream['url'], TIMEOUT_SECONDS, is_ppv)
                      
                      if result['status'] == 'working':
                          working_streams += 1
                          file_working += 1
                          print(f"  ‚úÖ Working ({result.get('type', 'Stream')})")
                      else:
                          print(f"  ‚ùå Failed: {result['error']}")
                          
                          # Categorize the failure
                          failure_info = {
                              'name': stream['name'],
                              'group': stream['group'],
                              'url': stream['url'][:80] + '...' if len(stream['url']) > 80 else stream['url'],
                              'file': m3u_file,
                              'error': result['error'],
                              'code': result['code'],
                              'type': 'PPV' if is_ppv else ('VOD' if is_vod_url(stream['url']) else 'Live')
                          }
                          
                          if result['status'] in categorized_failures:
                              categorized_failures[result['status']].append(failure_info)
                          else:
                              categorized_failures['unknown_error'].append(failure_info)
                      
                      # Dynamic delay based on success rate
                      if checked_streams % 10 == 0:
                          success_rate = working_streams / checked_streams
                          delay = 0.1 if success_rate > 0.8 else 0.2
                          time.sleep(delay)
                      else:
                          time.sleep(0.05)
                  
                  print(f"üìä File {m3u_file}: {file_working}/{file_total-file_skipped} working, {file_skipped} skipped")
                  
              except Exception as e:
                  print(f"‚ùå Error processing {m3u_file}: {str(e)}")
          
          # Calculate final statistics
          total_checked = checked_streams
          total_failures = sum(len(failures) for failures in categorized_failures.values())
          working_percentage = (working_streams / total_checked * 100) if total_checked > 0 else 0
          end_time = datetime.now(timezone.utc)
          duration = end_time - start_time
          
          print(f"‚è±Ô∏è Check completed in {duration.total_seconds():.1f} seconds")
          
          # Generate enhanced report
          report = f"""# üì∫ Enhanced M3U Stream Status Report
          
          **Generated on:** {end_time.strftime('%Y-%m-%d %H:%M:%S')} UTC  
          **Duration:** {duration.total_seconds():.1f} seconds  
          **Runner Location:** GitHub Actions (global infrastructure)  
          **Configuration:** VODs: {'‚úÖ' if CHECK_VODS else '‚ùå'}, PPV: {'‚úÖ' if CHECK_PPV else '‚ùå'}, Timeout: {TIMEOUT_SECONDS}s
          
          ## üìä Summary
          
          | Metric | Count | Percentage |
          |--------|-------|------------|
          | **Total Streams Found** | {total_streams} | 100% |
          | **üîç Checked Streams** | {total_checked} | {(total_checked/total_streams*100):.1f}% |
          | **‚úÖ Working Streams** | {working_streams} | {working_percentage:.1f}% |
          | **‚ùå Failed Streams** | {total_failures} | {(total_failures/total_checked*100):.1f if total_checked > 0 else 0:.1f}% |
          | **‚è≠Ô∏è Skipped Streams** | {skipped_streams} | {(skipped_streams/total_streams*100):.1f}% |
          
          ## üìÅ Files Processed
          
          """
          
          for m3u_file in m3u_files:
              if os.path.exists(m3u_file):
                  file_streams = parse_m3u(m3u_file)
                  report += f"- `{m3u_file}`: {len(file_streams)} streams\n"
          
          # Skipped streams section
          if skipped_streams > 0:
              report += f"""
          ## ‚è≠Ô∏è Skipped Streams ({skipped_streams} total)
          
          """
              
              if skipped_categories['vods'] and not CHECK_VODS:
                  report += f"""### üé¨ VOD Files ({len(skipped_categories['vods'])} skipped)
          *Enable "Check VODs" in workflow dispatch to test these*
          
          | Channel Name | Group | File |
          |-------------|-------|------|
          """
                  for item in skipped_categories['vods'][:20]:  # Limit to first 20
                      name = item['name'].replace('|', '\\|')
                      group = item['group'].replace('|', '\\|')
                      report += f"| {name} | {group} | {item['file']} |\n"
                  
                  if len(skipped_categories['vods']) > 20:
                      report += f"*... and {len(skipped_categories['vods']) - 20} more*\n"
                  report += "\n"
              
              if skipped_categories['ppv'] and not CHECK_PPV:
                  report += f"""### ü•ä PPV Channels ({len(skipped_categories['ppv'])} skipped)
          *Enable "Check PPV" in workflow dispatch to test these*
          
          | Channel Name | Group | File |
          |-------------|-------|------|
          """
                  for item in skipped_categories['ppv'][:10]:  # Limit to first 10
                      name = item['name'].replace('|', '\\|')
                      group = item['group'].replace('|', '\\|')
                      report += f"| {name} | {group} | {item['file']} |\n"
                  
                  if len(skipped_categories['ppv']) > 10:
                      report += f"*... and {len(skipped_categories['ppv']) - 10} more*\n"
                  report += "\n"
          
          # Enhanced failure analysis
          if total_failures > 0:
              failure_categories = {
                  'access_denied': ('üö´ Access Denied', 'Geo-blocked or authentication required'),
                  'timeout': ('‚è±Ô∏è Connection Timeouts', 'Server slow/overloaded or PPV preparing'),
                  'dns_error': ('üåê DNS Failures', 'Domain name resolution failed'),
                  'not_found': ('‚ùì Not Found (404)', 'Stream URL no longer exists'),
                  'server_error': ('üí• Server Errors (5xx)', 'Server-side technical issues'),
                  'connection_error': ('üîó Connection Errors', 'Network connectivity problems'),
                  'stream_error': ('üì∫ Stream Errors', 'Stream exists but unreadable'),
                  'rate_limited': ('üö´ Rate Limited', 'Too many requests'),
                  'http_error': ('üåç HTTP Errors', 'Other HTTP status codes'),
                  'unknown_error': ('‚ùì Unknown Errors', 'Unexpected errors')
              }
              
              report += f"""
          ## üìã Failure Analysis ({total_failures} total failures)
          
          """
              
              for category, failures in categorized_failures.items():
                  if failures:
                      title, description = failure_categories[category]
                      report += f"""### {title} ({len(failures)} streams)
          *{description}*
          
          | Channel | Group | Type | Error | Code | File |
          |---------|-------|------|-------|------|------|
          """
                      
                      for stream in failures:
                          name = stream['name'].replace('|', '\\|')[:30]
                          group = stream['group'].replace('|', '\\|')[:20]
                          stream_type = stream.get('type', 'Live')[:8]
                          error = (stream['error'] or 'Unknown').replace('|', '\\|')[:40]
                          code = stream['code'] if stream['code'] else 'N/A'
                          file_name = stream['file'].replace('|', '\\|')
                          
                          report += f"| {name} | {group} | {stream_type} | {error} | {code} | {file_name} |\n"
                      
                      report += "\n"
          
          else:
              report += """
          ## üéâ All Checked Streams Working!
          
          All tested streams are currently accessible from GitHub's infrastructure.
          """
          
          report += f"""
          ## üìã Configuration Notes
          
          - **VOD Checking:** {'Enabled' if CHECK_VODS else 'Disabled'} - VOD files (.mkv, .mp4, etc.) {'were' if CHECK_VODS else 'were not'} tested
          - **PPV Checking:** {'Enabled' if CHECK_PPV else 'Disabled'} - PPV/Event channels {'were' if CHECK_PPV else 'were not'} tested
          - **Timeout:** {TIMEOUT_SECONDS} seconds per stream (PPV channels get double timeout)
          
          ## üìà Geographic & Technical Notes
          
          - Tests run from **GitHub Actions** global infrastructure
          - "Access Denied" (403) errors typically indicate geo-restrictions
          - PPV channels may be offline between events (normal behavior)
          - VOD files are static content and should be consistently available
          - Timeout errors may indicate server overload or preparation time
          - DNS errors suggest the streaming service domain is down
          
          ## üîß Technical Details
          
          - **User-Agent:** Chrome 120 simulation for maximum compatibility
          - **Method:** HEAD for VODs, GET with stream verification for live content
          - **Headers:** Enhanced with security headers and proper content type
          - **Rate Limiting:** Dynamic delays based on success rate
          - **Retry Logic:** Single attempt per stream to avoid overwhelming servers
          
          ## üéõÔ∏è Manual Testing Options
          
          To test specific content types:
          1. Go to **Actions** ‚Üí **Check M3U Streams** ‚Üí **Run workflow**
          2. Toggle **Check VODs** to test .mkv/.mp4 files
          3. Toggle **Check PPV** to test Pay-Per-View channels
          4. Adjust **Timeout** for slower connections
          
          ---
          *Last updated: {end_time.strftime('%Y-%m-%d %H:%M:%S')} UTC*  
          *Report generated automatically by Enhanced GitHub Actions*
          """
          
          # Write report
          try:
              with open('report.md', 'w', encoding='utf-8') as f:
                  f.write(report)
              print("üìä Enhanced report generated successfully!")
              print(f"üìà Final Summary: {working_streams}/{total_checked} streams working ({working_percentage:.1f}%), {skipped_streams} skipped")
          except Exception as e:
              print(f"‚ùå Error writing report: {str(e)}")
          
          EOF
        
      - name: Commit and push report
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "github-actions[bot]"
          git add report.md
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            # Enhanced commit message with configuration info
            COMMIT_MSG="üìä Stream report"
            if [[ "$CHECK_VODS" == "true" ]]; then
              COMMIT_MSG="$COMMIT_MSG +VODs"
            fi
            if [[ "$CHECK_PPV" == "true" ]]; then
              COMMIT_MSG="$COMMIT_MSG +PPV"
            fi
            COMMIT_MSG="$COMMIT_MSG - $(date -u '+%Y-%m-%d %H:%M UTC')"
            
            git commit -m "$COMMIT_MSG"
            git push
          fi
